{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the goodies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn                                              \n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "torch.set_printoptions(linewidth = 120)\n",
    "torch.set_grad_enabled(True)\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "import numpy as np\n",
    "import pyautogui\n",
    "from PIL import Image \n",
    "from Xlib import display\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from mss.linux import MSS as mss\n",
    "import mss.tools\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the nn layers and loading up the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(3, 7, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (conv2): Conv2d(7, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=70, out_features=60, bias=True)\n",
      "  (fc2): Linear(in_features=60, out_features=50, bias=True)\n",
      "  (fc3): Linear(in_features=50, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 7, 5)\n",
    "        self.pool = nn.MaxPool2d(3, 3)\n",
    "        \n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        self.conv2 = nn.Conv2d(7, 10, 5)\n",
    "        \n",
    "        \n",
    "        self.fc1 = nn.Linear(70, 60)\n",
    "        self.fc2 = nn.Linear(60, 50)\n",
    "        self.fc3 = nn.Linear(50, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.dropout(self.pool(F.relu(self.conv1(x))))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "drunk_driver = Net()\n",
    "print(drunk_driver)\n",
    "drunk_driver = torch.load(\"torch/fpv.pth\")\n",
    "drunk_driver = drunk_driver.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining some utilities "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def preprocess_live(img_obj, show = False):\n",
    "    \n",
    "    np_im = np.array(img_obj)\n",
    "    if show == True:\n",
    "        plt.imshow(np_im)\n",
    "        plt.show()\n",
    "    np_im = np.moveaxis(np_im, 2,0)\n",
    "    inp = torch.from_numpy(np_im).unsqueeze(0).float()  ## tensor ready to be fed to nn \n",
    "    return inp \n",
    "\n",
    "def image_to_result(img_path):\n",
    "    \n",
    "    im_tensor = preprocess(img_path, show = True)\n",
    "    res = drunk_driver(im_tensor).item()\n",
    "    \n",
    "    print(res)\n",
    "    \n",
    "def capture_resize_to_pil(co_ord, size = (100,100)):\n",
    "    \n",
    "    im = pyautogui.screenshot(region = co_ord ).resize((size), Image.ANTIALIAS)\n",
    "    return im\n",
    "\n",
    "def make_a_decision(image):  ## image to steer  val \n",
    "    \n",
    "    im_tensor = preprocess_live(image, show = False)\n",
    "    res = drunk_driver(im_tensor).item()\n",
    "    return res\n",
    "\n",
    "def find_mouse(x = False , y = False):\n",
    "    \n",
    "    data = display.Display().screen().root.query_pointer()._data\n",
    "    res = [data[\"root_x\"], data[\"root_y\"]]\n",
    "    if x == True and y == True:\n",
    "        return res\n",
    "    elif x == True and y == False:\n",
    "        return res[0]\n",
    "    else:\n",
    "        return res[1]\n",
    "\n",
    "def move_mouse_co_ord_x(x_val , time = 0.001):\n",
    "    \n",
    "    current_y = find_mouse(y = True)\n",
    "    pyautogui.moveTo(x_val, current_y, duration= time )\n",
    "    \n",
    "\n",
    "def screen_record_efficient(top = 225, left = 0, width = 800, height = 260, resize_width = 80, resize_height = 25):\n",
    "  \n",
    "    mon = {\"top\": top, \"left\": left, \"width\": width, \"height\": height}\n",
    "    sct = mss.mss()\n",
    "    \n",
    "    img = np.array(sct.grab(mon))\n",
    "    img = cv2.resize(img, (80,25))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGRA2RGB)\n",
    "    sct.close()\n",
    "    return img\n",
    "\n",
    "\n",
    "def numpy_resize_to_input_channel_size(np_im, height = 560, width = 800, show = False):\n",
    "    \n",
    "    if show == True:\n",
    "        plt.imshow(np_im)\n",
    "        plt.show()\n",
    "        \n",
    "    np_im = np.moveaxis(np_im, 2,0)\n",
    "    inp = torch.from_numpy(np_im).unsqueeze(0).float()  ## tensor ready to be fed to nn \n",
    "    return inp \n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## And it all comes together here\n",
    "> * Feel free to change the vertices in `screen_record_efficient()` depending on where you place the game window on the screen\n",
    "*  Drag mouse to the corner of the screen to quit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def not_so_drunk_driver():\n",
    "    \n",
    "    print (\"running...\")\n",
    "    print (\"drag mouse to the corner of the screen to terminate -\")\n",
    "    while True:\n",
    "        try:\n",
    "            foo = screen_record_efficient(top = 225,width = 800, height = 260, resize_width = 80, resize_height = 25)  ## FPV TRACK VIEW \n",
    "            foo = numpy_resize_to_input_channel_size(foo, show = False)\n",
    "            steer = int(drunk_driver(foo).item())\n",
    "            x_co = 400 - steer\n",
    "\n",
    "\n",
    "            move_mouse_co_ord_x(x_co , time = 0)\n",
    "\n",
    "\n",
    "        except:\n",
    "          \n",
    "\n",
    "            print(\"end ----\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running...\n",
      "drag mouse to the corner of the screen to terminate -\n",
      "end ----\n"
     ]
    }
   ],
   "source": [
    "not_so_drunk_driver()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
